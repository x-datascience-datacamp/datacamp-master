{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66673d54-8394-4c9f-8df9-ee9c3d39cd32",
   "metadata": {},
   "source": [
    "# Encoding complex data with fuzzy logic \n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tommoral/24-sacl-ai-4-sciences/blob/main/session-3/01-complex-tabular-data.ipynb)\n",
    "\n",
    "Authors: Thomas Moreau, Mathurin Massias\n",
    "\n",
    "In this notebook we briefly highlight some features of [`skrub`](https://skrub-data.org), a package to preprocess and handle text data in ML pipelines.\n",
    "\n",
    "If you have not done so, please install [`skrub`](https://skrub-data.org) by uncommenting the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn skrub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8768e",
   "metadata": {},
   "source": [
    "We will work with public servant data from the US administration, that you can load with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8be97-9326-4cc4-8473-eb35b6525968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "DATA_FILE = \"data/salary_X.parquet\"\n",
    "URL_REPO = \"https://github.com/x-datascience-datacamp/datacamp-master/raw/main/06-feature_engineering/\"\n",
    "\n",
    "if Path(DATA_FILE).exists():\n",
    "    data_file = DATA_FILE\n",
    "else:\n",
    "    data_file = f\"{URL_REPO}{DATA_FILE}\"\n",
    "\n",
    "# Loading data\n",
    "X = pd.read_parquet(data_file).drop(columns='Unnamed: 0')\n",
    "y = pd.read_parquet(data_file.replace(\"_X\", \"_y\")).drop(columns='Unnamed: 0')\n",
    "\n",
    "print(f'Number of entries & columns in X: {X.shape}')\n",
    "print(X.columns, y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695c6c5-413b-43a4-9bb3-3ec8bff680d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4086c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79deb1",
   "metadata": {},
   "source": [
    "Across the administration, the position titles can have similar levels but are not unique.\n",
    "Also, in some position name, the grade is actually encoded:  `Social Worker IV`, `Resident Supervisor II`, ...\n",
    "With this, there is a large number of categories that have some similarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['employee_position_title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00814da3",
   "metadata": {},
   "source": [
    "If we can learn a model with only with these categories, we can see that some categories have not been seen at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel())\n",
    "\n",
    "model = make_pipeline(\n",
    "    make_column_transformer((OrdinalEncoder(), ['employee_position_title'])),\n",
    "    HistGradientBoostingRegressor()\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7cea30",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "         <li>Fix the behavior of `OrdinalEncoder` to allow the model to predict even in the case where some categories are present in the test set and not in the train one.</li>\n",
    "    </ul>\n",
    "    \n",
    "   *Hint:* you can look at the documentation of the [`OrdinalEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) to see how to handle missing categories.\n",
    "</div>\n",
    "\n",
    "Solution: `solutions/01-1_encode_unknown_values.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c05d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df027bf8",
   "metadata": {},
   "source": [
    "### Handeling fuzzy categories with `skrub`\n",
    "\n",
    "In order to leverage the high cardinality categories with similar texts, [`skrub`](https://skrub-data.org/) provide the `GapEncoder`, which performs some fuzy text matching, based on their similarity scores from n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c63ec8-3556-4910-a874-1826af6d9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skrub import GapEncoder\n",
    "\n",
    "# defining data\n",
    "data = pd.Series([\n",
    "    \"Math, optimization\",\n",
    "    \"mathematics\",\n",
    "    \"maths, ml\",\n",
    "    \"ml.maths\",\n",
    "    \"machine learning\",\n",
    "    \"physics\",\n",
    "    \"phy\",\n",
    "    \"statistical physics\",\n",
    "    \"computational phys.\",\n",
    "    \"comp. maths\"\n",
    "]\n",
    ")\n",
    "\n",
    "gap_encoder = GapEncoder(n_components=2, random_state=42)\n",
    "encoded_data = gap_encoder.fit_transform(data)\n",
    "print(gap_encoder.get_feature_names_out())\n",
    "\n",
    "encoded_data['original'] = data\n",
    "encoded_data = encoded_data.set_index('original')\n",
    "encoded_data.columns = [0, 1]\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303bd781",
   "metadata": {},
   "source": [
    "To regress the annual salary of each worker based on their title, you can thus transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3d5e1-2e02-48d7-b65b-797c6261c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel())\n",
    "\n",
    "model = make_pipeline(\n",
    "    make_column_transformer((GapEncoder(n_components=30), 'employee_position_title')),\n",
    "    HistGradientBoostingRegressor()\n",
    ")\n",
    "model.fit(X_train, y_train).score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gapencoder = model[0]\n",
    "gapencoder.named_transformers_['gapencoder'].get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3199f1",
   "metadata": {},
   "source": [
    "### Automatized feature extraction with complex tabular data\n",
    "\n",
    "The original data contains various columns, with categorical features and dates.\n",
    "[`skrub`](https://skrub-data.org/) provides a convenient tools to directly vectorize the full tables with reasonable defaults:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b9f11-5f46-43bb-a3e6-e966b6782aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skrub import TableVectorizer\n",
    "\n",
    "\n",
    "# defining pipeline\n",
    "model = make_pipeline(\n",
    "    TableVectorizer(),\n",
    "    HistGradientBoostingRegressor()\n",
    ")\n",
    "\n",
    "# fitting model\n",
    "model.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92887895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving fitted vectorizer\n",
    "model.named_steps['tablevectorizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535cbc6",
   "metadata": {},
   "source": [
    "But the default preprocessing choices depends on the actual classifier which is put after the `TableVectorizer`.\n",
    "For this, [`skrub`](https://skrub-data.org/) exposes an helper `make_tabular_model` which change the default based on the actual classifier which is chosen.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "         <li>Construct a pipeline with `tabular_learner` for a `Ridge` estimator.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Solution: `solutions/01-2_encode_unknown_values.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c3628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
